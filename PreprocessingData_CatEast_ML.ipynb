{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIBRARY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SPLIT DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Direktori Dataset\n",
    "cat_disease_dir = \"/content/CAT SKIN DISEASE\" \n",
    "train_dir = \"/content\"\n",
    "val_dir = \"/content\"\n",
    "test_dir = \"/content\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Buat Folder Traininng, Validation, dan Test\n",
    "os.makedirs(train_dir, exist_ok=True)\n",
    "os.makedirs(val_dir, exist_ok=True)\n",
    "os.makedirs(test_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mengambil semua gambar dari Dataset\n",
    "all_images = os.listdir(cat_disease_dir)\n",
    "random.shuffle(all_images) # Mengacak urutan gambar\n",
    "\n",
    "# Menentukan bagian untuk Training, Validation, dan Test\n",
    "split_train = 0.7\n",
    "split_val = 0.15\n",
    "split_test = 0.15\n",
    "\n",
    "# Hitung indeks\n",
    "index_train = int(len(all_images) * split_train)\n",
    "index_val = index_train + int(len(all_images) * split_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Memindahkan gambar ke Folder yang sudah dibuat\n",
    "for i, image in enumerate(all_images):\n",
    "    src_path = os.path.join(cat_disease_dir, image)\n",
    "    if i < split_train:\n",
    "        shutil.copy(src_path, train_dir)\n",
    "    elif i < split_val:\n",
    "        shutil.copy(src_path, val_dir)\n",
    "    else:\n",
    "        shutil.copy(src_path, test_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PREPROCESS TRAIN DAN VALIDATION DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Membuat Traininng Dataset\n",
    "train_dataset = tf.keras.utils.image_dataset_from_dir(train_dir, \n",
    "                                                      image_size=(100, 100), \n",
    "                                                      batch_size=32, \n",
    "                                                      label_mode='binary')\n",
    "\n",
    "# Membuat Validation Dataset\n",
    "val_dataset = tf.keras.utils.image_dataset_from_dir(val_dir, \n",
    "                                                    image_size=(100, 100), \n",
    "                                                    batch_size=32, \n",
    "                                                    label_mode='binary')\n",
    "\n",
    "# Optimisasi Dataset\n",
    "SHUFFLE_BUFFER_SIZE = 100\n",
    "PREFETCH_BUFFER_SIZE = tf.data.AUTOTUNE\n",
    "\n",
    "train_dataset_fin = (train_dataset\n",
    "                     .cache()\n",
    "                     .shuffle(SHUFFLE_BUFFER_SIZE)\n",
    "                     .prefetch(PREFETCH_BUFFER_SIZE))\n",
    "\n",
    "train_dataset_fin = (train_dataset\n",
    "                     .cache()\n",
    "                     .shuffle(SHUFFLE_BUFFER_SIZE)\n",
    "                     .prefetch(PREFETCH_BUFFER_SIZE))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
